{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Визуализация калибровки LiDAR ↔️ Камера\n\nЭтот ноутбук демонстрирует два типичных шага при работе с `BEVCalib`:\n1. Как выглядит лидарное облако точек при раскалибровке и после корректной калибровки.\n2. Как можно получить проекцию Bird's-Eye View (BEV) как из облака точек, так и из изображения."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Импорт библиотек и настройки\nВ примере используются только стандартные библиотеки Python и зависимости, уже имеющиеся в проекте."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D  # noqa: F401 - необходим для 3D-графиков\nimport cv2\n\nnp.random.seed(42)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Синтетическое облако точек\nЧтобы не зависеть от данных KITTI, создадим небольшую синтетическую сцену: плоскость дороги, прямоугольник автомобиля и столб."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def create_synthetic_scene():\n    # Плоскость дороги (решетка точек)\n    ground_x = np.linspace(0, 30, 20)\n    ground_y = np.linspace(-10, 10, 25)\n    gx, gy = np.meshgrid(ground_x, ground_y)\n    ground = np.stack([gx.ravel(), gy.ravel(), np.zeros_like(gx).ravel()], axis=1)\n\n    # Параллелепипед автомобиля\n    car_x = np.linspace(8, 12, 8)\n    car_y = np.linspace(-1.2, 1.2, 6)\n    car_z = np.linspace(0, 1.6, 6)\n    cx, cy, cz = np.meshgrid(car_x, car_y, car_z)\n    car = np.stack([cx, cy, cz], axis=-1).reshape(-1, 3)\n    car_shell = car[(np.isclose(car[:, 0], car_x[0])) |\n                    (np.isclose(car[:, 0], car_x[-1])) |\n                    (np.isclose(car[:, 1], car_y[0])) |\n                    (np.isclose(car[:, 1], car_y[-1])) |\n                    (np.isclose(car[:, 2], car_z[-1]))]\n\n    # Столб/дерево\n    pole_z = np.linspace(0, 4, 30)\n    pole = np.stack([np.full_like(pole_z, 18.0),\n                     np.full_like(pole_z, 5.0),\n                     pole_z], axis=1)\n\n    points = np.vstack([ground, car_shell, pole])\n    points += np.random.normal(scale=0.03, size=points.shape)\n    return points\n\npoints_lidar = create_synthetic_scene()\npoints_lidar.shape"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Экстринсики и раскалибровка\nОпределим истинные параметры (вращение + перенос) и добавим шум, имитирующий раскалибровку."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def rotation_matrix(roll=0.0, pitch=0.0, yaw=0.0):\n    cr, sr = np.cos(roll), np.sin(roll)\n    cp, sp = np.cos(pitch), np.sin(pitch)\n    cy, sy = np.cos(yaw), np.sin(yaw)\n\n    rot_x = np.array([[1, 0, 0],\n                      [0, cr, -sr],\n                      [0, sr, cr]])\n    rot_y = np.array([[cp, 0, sp],\n                      [0, 1, 0],\n                      [-sp, 0, cp]])\n    rot_z = np.array([[cy, -sy, 0],\n                      [sy, cy, 0],\n                      [0, 0, 1]])\n    return rot_z @ rot_y @ rot_x\n\n\ndef make_extrinsic(rotation, translation):\n    extrinsic = np.eye(4)\n    extrinsic[:3, :3] = rotation\n    extrinsic[:3, 3] = translation\n    return extrinsic\n\n\ndef apply_extrinsic(points, extrinsic):\n    points_h = np.hstack([points, np.ones((points.shape[0], 1))])\n    transformed = points_h @ extrinsic.T\n    return transformed[:, :3]\n\n\ntrue_rotation = rotation_matrix(roll=np.deg2rad(-1.5),\n                                pitch=np.deg2rad(1.0),\n                                yaw=np.deg2rad(2.5))\ntrue_translation = np.array([0.25, -0.45, 1.75])\ntrue_extrinsic = make_extrinsic(true_rotation, true_translation)\n\nmiscal_rotation = rotation_matrix(roll=np.deg2rad(1.2),\n                                  pitch=np.deg2rad(-2.0),\n                                  yaw=np.deg2rad(4.5))\nmiscal_translation = true_translation + np.array([0.35, 0.25, -0.18])\nmiscalibrated_extrinsic = make_extrinsic(miscal_rotation, miscal_translation)\n\n# После калибровки мы стремимся восстановить истинные параметры.\npoints_in_camera_miscal = apply_extrinsic(points_lidar, miscalibrated_extrinsic)\npoints_in_camera_calibrated = apply_extrinsic(points_lidar, true_extrinsic)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Сравнение облаков точек\nНа графиках ниже показано, как одна и та же сцена выглядит в системе координат камеры до и после калибровки."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "%matplotlib inline\n\n\ndef set_axes_equal(ax):\n    limits = np.array([\n        ax.get_xlim3d(),\n        ax.get_ylim3d(),\n        ax.get_zlim3d(),\n    ])\n    spans = limits[:, 1] - limits[:, 0]\n    centers = np.mean(limits, axis=1)\n    radius = 0.5 * max(spans)\n    ax.set_xlim3d([centers[0] - radius, centers[0] + radius])\n    ax.set_ylim3d([centers[1] - radius, centers[1] + radius])\n    ax.set_zlim3d([centers[2] - radius, centers[2] + radius])\n\n\nfig = plt.figure(figsize=(14, 6))\nax1 = fig.add_subplot(121, projection='3d')\nax1.scatter(points_in_camera_miscal[:, 0],\n           points_in_camera_miscal[:, 1],\n           points_in_camera_miscal[:, 2],\n           c='tomato', s=6, alpha=0.7)\nax1.set_title('До калибровки')\nax1.set_xlabel('X (камера)')\nax1.set_ylabel('Y (камера)')\nax1.set_zlabel('Z (камера)')\nset_axes_equal(ax1)\n\nax2 = fig.add_subplot(122, projection='3d')\nax2.scatter(points_in_camera_calibrated[:, 0],\n           points_in_camera_calibrated[:, 1],\n           points_in_camera_calibrated[:, 2],\n           c='royalblue', s=6, alpha=0.7)\nax2.set_title('После калибровки')\nax2.set_xlabel('X (камера)')\nax2.set_ylabel('Y (камера)')\nax2.set_zlabel('Z (камера)')\nset_axes_equal(ax2)\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## BEV из облака точек\nДля Bird's-Eye View используем простую гистограмму по сетке $x, y$, где значение ячейки показывает количество точек."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def compute_bev(points, x_limits=(0, 30), y_limits=(-10, 10), resolution=0.2):\n    mask = (\n        (points[:, 0] >= x_limits[0]) & (points[:, 0] <= x_limits[1]) &\n        (points[:, 1] >= y_limits[0]) & (points[:, 1] <= y_limits[1])\n    )\n    filtered = points[mask]\n    x_bins = int(np.ceil((x_limits[1] - x_limits[0]) / resolution))\n    y_bins = int(np.ceil((y_limits[1] - y_limits[0]) / resolution))\n    bev = np.zeros((y_bins, x_bins), dtype=np.float32)\n\n    x_idx = ((filtered[:, 0] - x_limits[0]) / resolution).astype(int)\n    y_idx = ((filtered[:, 1] - y_limits[0]) / resolution).astype(int)\n    np.add.at(bev, (y_idx, x_idx), 1)\n    bev /= bev.max() + 1e-6\n    return bev\n\n\nbev_from_lidar = compute_bev(points_in_camera_calibrated)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(bev_from_lidar, origin='lower', cmap='viridis',\n           extent=[0, 30, -10, 10])\nplt.colorbar(label='Нормированная плотность точек')\nplt.title('BEV из LiDAR (после калибровки)')\nplt.xlabel('X, м (вперёд)')\nplt.ylabel('Y, м (влево)')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## BEV из изображения\nСымитируем камеру: зададим BEV-карту дороги, спроецируем её в перспективу, а затем восстановим BEV посредством обратного преобразования."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def create_synthetic_bev(size=400):\n    bev = np.zeros((size, size, 3), dtype=np.uint8)\n    # Дорога\n    cv2.rectangle(bev, (60, 0), (size - 60, size), (80, 80, 80), thickness=-1)\n    # Полоса безопасности\n    cv2.rectangle(bev, (0, 0), (60, size), (30, 30, 30), thickness=-1)\n    cv2.rectangle(bev, (size - 60, 0), (size, size), (30, 30, 30), thickness=-1)\n    # Линии разметки\n    for offset in [size // 2 - 60, size // 2, size // 2 + 60]:\n        for start in range(0, size, 40):\n            cv2.rectangle(bev, (offset - 4, start), (offset + 4, start + 20),\n                          (230, 230, 230), thickness=-1)\n    return bev\n\n\nbev_template = create_synthetic_bev(400)\n\n# Гомография из BEV в перспективу (имитируем вид фронтальной камеры)\nsrc = np.float32([[0, 399], [399, 399], [320, 220], [80, 220]])\ndst = np.float32([[120, 359], [520, 359], [420, 60], [220, 60]])\nH = cv2.getPerspectiveTransform(src, dst)\n\nperspective_image = cv2.warpPerspective(bev_template, H, (640, 360))\nH_inv = np.linalg.inv(H)\nbev_from_image = cv2.warpPerspective(perspective_image, H_inv, (400, 400))\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\naxes[0].imshow(cv2.cvtColor(bev_template, cv2.COLOR_BGR2RGB))\naxes[0].set_title('Заданная BEV-карта')\naxes[0].axis('off')\n\naxes[1].imshow(cv2.cvtColor(perspective_image, cv2.COLOR_BGR2RGB))\naxes[1].set_title('Синтетическое изображение камеры')\naxes[1].axis('off')\n\naxes[2].imshow(cv2.cvtColor(bev_from_image, cv2.COLOR_BGR2RGB))\naxes[2].set_title('BEV, восстановленное из изображения')\naxes[2].axis('off')\n\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Сопоставление BEV из LiDAR и изображения\nДля визуального сравнения можно совместить карты. Ниже показана простая альфа-композиция."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "bev_lidar_color = plt.cm.viridis(bev_from_lidar)[:, :, :3]\nbev_lidar_rgb = (bev_lidar_color * 255).astype(np.uint8)\n\n# Приводим размеры к одному разрешению\nbev_lidar_resized = cv2.resize(bev_lidar_rgb, (400, 400), interpolation=cv2.INTER_LINEAR)\ncombined = cv2.addWeighted(bev_lidar_resized, 0.6,\n                           cv2.cvtColor(bev_from_image, cv2.COLOR_BGR2RGB), 0.4, 0)\n\nplt.figure(figsize=(6, 6))\nplt.imshow(combined)\nplt.title('Совмещение BEV из LiDAR и изображения')\nplt.axis('off')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Выводы\n- На синтетическом примере видно, как смещения и вращения экстринсиков искажают облако точек и как калибровка их исправляет.\n- Простая гистограмма по сетке позволяет получить BEV-представление из LiDAR.\n- Гомография демонстрирует принцип получения BEV из изображения — ключевая идея `BEVCalib`."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}